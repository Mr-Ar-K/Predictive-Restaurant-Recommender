{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80231c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/codespace/.local/lib/python3.12/site-packages (from lightgbm) (2.3.1)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from lightgbm) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install lightgbm if not already installed\n",
    "%pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56877e42",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c6f34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "print(\"added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064487fc",
   "metadata": {},
   "source": [
    "### Loading of the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474b2d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully.\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    train_orders = pd.read_csv('Train/orders.csv', low_memory=False)\n",
    "    train_customers = pd.read_csv('Train/train_customers.csv')\n",
    "    train_locations = pd.read_csv('Train/train_locations.csv')\n",
    "    vendors = pd.read_csv('Train/vendors.csv')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Make sure all CSV files are in the same directory as the script.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c8dcf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22172/2751923399.py:5: DtypeWarning: Columns (15,16,18,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_orders = pd.read_csv('Train/orders.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing and merging data...\n",
      "\n",
      "Columns in train_merged:\n",
      "['order_id', 'customer_id', 'item_count', 'grand_total', 'payment_mode', 'promo_code', 'vendor_discount_amount', 'promo_code_discount_percentage', 'is_favorite', 'is_rated', 'vendor_rating_x', 'driver_rating', 'deliverydistance', 'preparationtime', 'delivery_time', 'order_accepted_time', 'driver_accepted_time', 'ready_for_pickup_time', 'picked_up_time', 'delivered_time', 'delivery_date', 'vendor_id', 'created_at_x', 'LOCATION_NUMBER', 'LOCATION_TYPE', 'CID X LOC_NUM X VENDOR', 'gender', 'dob', 'status', 'verified_x', 'language_x', 'created_at_y', 'updated_at_x', 'id', 'authentication_id', 'vendor_lat', 'vendor_lon', 'vendor_category_en', 'vendor_category_id', 'delivery_charge', 'serving_distance', 'is_open', 'OpeningTime', 'OpeningTime2', 'prepration_time', 'commission', 'is_haked_delivering', 'discount_percentage', 'vendor_status', 'verified_y', 'rank', 'language_y', 'vendor_rating_y', 'sunday_from_time1', 'sunday_to_time1', 'sunday_from_time2', 'sunday_to_time2', 'monday_from_time1', 'monday_to_time1', 'monday_from_time2', 'monday_to_time2', 'tuesday_from_time1', 'tuesday_to_time1', 'tuesday_from_time2', 'tuesday_to_time2', 'wednesday_from_time1', 'wednesday_to_time1', 'wednesday_from_time2', 'wednesday_to_time2', 'thursday_from_time1', 'thursday_to_time1', 'thursday_from_time2', 'thursday_to_time2', 'friday_from_time1', 'friday_to_time1', 'friday_from_time2', 'friday_to_time2', 'saturday_from_time1', 'saturday_to_time1', 'saturday_from_time2', 'saturday_to_time2', 'primary_tags', 'open_close_flags', 'vendor_tag', 'vendor_tag_name', 'one_click_vendor', 'country_id', 'city_id', 'created_at', 'updated_at_y', 'device_type', 'display_orders', 'location_number', 'location_type', 'customer_lat', 'customer_lon']\n",
      "\n",
      "--- Training Data Ready ---\n",
      "Final training data has 395867 rows and 22 columns.\n",
      "Columns: ['customer_id', 'vendor_id', 'gender', 'dob', 'status', 'created_at_x', 'vendor_category_en', 'delivery_charge', 'serving_distance', 'is_open', 'prepration_time', 'commission', 'discount_percentage', 'vendor_status', 'rank', 'vendor_tag_name', 'is_favorite', 'LOCATION_TYPE', 'customer_lat', 'customer_lon', 'vendor_lat', 'vendor_lon']\n",
      "\n",
      "Sample of the final training data:\n",
      "  customer_id  vendor_id gender  dob  status   created_at_x  \\\n",
      "0     KL09J9N         84   Male  NaN     1.0  8/2/2024 5:33   \n",
      "1     KL09J9N         84   Male  NaN     1.0  8/2/2024 5:33   \n",
      "2     KL09J9N         84   Male  NaN     1.0  8/2/2024 5:33   \n",
      "3     KL09J9N         84   Male  NaN     1.0  8/2/2024 5:33   \n",
      "4     H5LGGFX         78   Male  NaN     1.0  8/2/2024 5:34   \n",
      "\n",
      "  vendor_category_en  delivery_charge  serving_distance  is_open  ...  \\\n",
      "0        Restaurants              0.0                15        1  ...   \n",
      "1        Restaurants              0.0                15        1  ...   \n",
      "2        Restaurants              0.0                15        1  ...   \n",
      "3        Restaurants              0.0                15        1  ...   \n",
      "4        Restaurants              0.7                15        0  ...   \n",
      "\n",
      "   discount_percentage  vendor_status  rank  \\\n",
      "0                    0              1    11   \n",
      "1                    0              1    11   \n",
      "2                    0              1    11   \n",
      "3                    0              1    11   \n",
      "4                    0              0    11   \n",
      "\n",
      "                                     vendor_tag_name  is_favorite  \\\n",
      "0                   Burgers,Fries,Kids meal,Shawarma          NaN   \n",
      "1                   Burgers,Fries,Kids meal,Shawarma          NaN   \n",
      "2                   Burgers,Fries,Kids meal,Shawarma          NaN   \n",
      "3                   Burgers,Fries,Kids meal,Shawarma          NaN   \n",
      "4  Pizzas,Italian,Breakfast,Soups,Pasta,Salads,De...          NaN   \n",
      "\n",
      "  LOCATION_TYPE customer_lat customer_lon  vendor_lat  vendor_lon  \n",
      "0          Work    -0.090650   -78.580196   -1.004923    0.078736  \n",
      "1          Work    -0.676098   -78.511007   -1.004923    0.078736  \n",
      "2          Work   -96.407541    43.557974   -1.004923    0.078736  \n",
      "3          Work    -0.089966     0.874226   -1.004923    0.078736  \n",
      "4          Home     1.733950   -78.795830   -0.555404    0.196336  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Merged training data saved to Train/train_merged.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "\n",
    "try:\n",
    "    # --- Load all source files ---\n",
    "    train_orders = pd.read_csv('Train/orders.csv')\n",
    "    train_customers = pd.read_csv('Train/train_customers.csv')\n",
    "    train_locations = pd.read_csv('Train/train_locations.csv')\n",
    "    vendors = pd.read_csv('Train/vendors.csv')\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"Please ensure all CSV files are in the correct 'Train/' subdirectory.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Preparing and merging data...\")\n",
    "\n",
    "# --- Rename columns BEFORE merging to avoid confusion ('_x', '_y') ---\n",
    "vendors.rename(columns={\n",
    "    'latitude': 'vendor_lat',\n",
    "    'longitude': 'vendor_lon',\n",
    "    'status': 'vendor_status',\n",
    "    'rating': 'vendor_rating'\n",
    "}, inplace=True)\n",
    "\n",
    "train_locations.rename(columns={\n",
    "    'latitude': 'customer_lat',\n",
    "    'longitude': 'customer_lon'\n",
    "}, inplace=True)\n",
    "\n",
    "# --- Merge all training data sources ---\n",
    "# Start with orders and add details about the customer, vendor, and location\n",
    "train_merged = train_orders.merge(train_customers, on='customer_id', how='left')\n",
    "train_merged = train_merged.merge(vendors, left_on='vendor_id', right_on='id', how='left')\n",
    "train_merged = train_merged.merge(\n",
    "    train_locations,\n",
    "    on=['customer_id'],  # Only merge on customer_id\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Debug: print columns to check for missing/misnamed columns\n",
    "print(\"\\nColumns in train_merged:\")\n",
    "print(train_merged.columns.tolist())\n",
    "\n",
    "# --- Define the specific columns required for training a model ---\n",
    "# These features are known at the time of prediction and avoid data leakage\n",
    "required_columns = [\n",
    "    # --- IDs (for context, not as model features) ---\n",
    "    'customer_id',\n",
    "    'vendor_id',\n",
    "    # 'LOCATION_NUMBER',  # Remove if not present\n",
    "\n",
    "    # --- Customer Features ---\n",
    "    'gender',\n",
    "    'dob',                         # To calculate customer age\n",
    "    'status',                      # Customer account status\n",
    "    'created_at_x',                # To calculate customer tenure (from customers table)\n",
    "\n",
    "    # --- Vendor Features ---\n",
    "    'vendor_category_en',\n",
    "    'delivery_charge',\n",
    "    'serving_distance',\n",
    "    'is_open',\n",
    "    'prepration_time',             # Vendor's average preparation time\n",
    "    'commission',\n",
    "    'discount_percentage',\n",
    "    'vendor_status',               # Vendor's account status\n",
    "    'rank',\n",
    "    # 'vendor_rating',               # Vendor's overall historical rating (removed)\n",
    "    'vendor_tag_name',             # Descriptive tags like 'Healthy', 'Pizza'\n",
    "\n",
    "    # --- Location & Interaction Features ---\n",
    "    'is_favorite',                 # If the customer has favorited this vendor\n",
    "    'LOCATION_TYPE',               # e.g., 'Home', 'Work'\n",
    "    'customer_lat',\n",
    "    'customer_lon',\n",
    "    'vendor_lat',\n",
    "    'vendor_lon',\n",
    "]\n",
    "\n",
    "# --- Create the final training dataframe with only the required columns ---\n",
    "# Keep all rows, even those with missing values\n",
    "final_training_df = train_merged[required_columns].reset_index(drop=True)\n",
    "\n",
    "print(\"\\n--- Training Data Ready ---\")\n",
    "print(f\"Final training data has {final_training_df.shape[0]} rows and {final_training_df.shape[1]} columns.\")\n",
    "print(\"Columns:\", final_training_df.columns.tolist())\n",
    "print(\"\\nSample of the final training data:\")\n",
    "print(final_training_df.head())\n",
    "\n",
    "# Save the final DataFrame to CSV\n",
    "final_training_df.to_csv('Train/train_merged.csv', index=False)\n",
    "print(\"\\nMerged training data saved to Train/train_merged.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c71514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering and test set functions defined.\n"
     ]
    }
   ],
   "source": [
    "def feature_engineer(df):\n",
    "    \"\"\"Creates new, predictive features from existing columns.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    if 'dob' in df.columns:\n",
    "        df['customer_age'] = 2025 - pd.to_numeric(df['dob'], errors='coerce')\n",
    "        df['customer_age'].fillna(df['customer_age'].median(), inplace=True)\n",
    "    \n",
    "    if 'created_at_x' in df.columns:\n",
    "        try:\n",
    "            df['customer_tenure_days'] = (datetime(2025, 7, 28) - pd.to_datetime(df['created_at_x'], errors='coerce')).dt.days\n",
    "            df['customer_tenure_days'].fillna(0, inplace=True)\n",
    "        except:\n",
    "            df['customer_tenure_days'] = 0\n",
    "    \n",
    "    if 'customer_lat' in df.columns and 'vendor_lat' in df.columns:\n",
    "        df['distance'] = np.sqrt((df['customer_lat'] - df['vendor_lat'])**2 + (df['customer_lon'] - df['vendor_lon'])**2)\n",
    "        df['distance'].fillna(df['distance'].median(), inplace=True)\n",
    "    \n",
    "    if 'vendor_tag_name' in df.columns:\n",
    "        df['vendor_tag_count'] = df['vendor_tag_name'].fillna('').astype(str).str.count(',') + 1\n",
    "        df['vendor_tag_count'].fillna(0, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_test_set(data_path='Test/'):\n",
    "    \"\"\"Loads and prepares the test data by creating all possible recommendations.\"\"\"\n",
    "    print(\"\\nPreparing test set...\")\n",
    "    try:\n",
    "        test_locations = pd.read_csv(f'{data_path}test_locations.csv')\n",
    "        customers = pd.read_csv('Train/train_customers.csv')\n",
    "        vendors = pd.read_csv('Train/vendors.csv')\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"Creating mock test set from training data...\")\n",
    "        # Create a mock test set from existing data\n",
    "        customers = pd.read_csv('Train/train_customers.csv')\n",
    "        vendors = pd.read_csv('Train/vendors.csv')\n",
    "        locations = pd.read_csv('Train/train_locations.csv')\n",
    "        \n",
    "        # Sample some customers and locations for testing\n",
    "        test_customers = customers.sample(n=min(100, len(customers)), random_state=42)\n",
    "        test_locations = locations[locations['customer_id'].isin(test_customers['customer_id'])].copy()\n",
    "        \n",
    "        test_df = pd.merge(test_locations, test_customers, on='customer_id', how='left')\n",
    "        test_df['key'] = 1\n",
    "        vendors['key'] = 1\n",
    "        test_df = pd.merge(test_df, vendors, on='key').drop('key', axis=1)\n",
    "        \n",
    "        test_df.rename(columns={\n",
    "            'latitude_x': 'customer_lat', 'longitude_x': 'customer_lon', \n",
    "            'latitude_y': 'vendor_lat', 'longitude_y': 'vendor_lon', \n",
    "            'status_y': 'vendor_status'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        print(f\"‚úÖ Mock test set created with {len(test_df)} potential recommendations.\")\n",
    "        return test_df\n",
    "    \n",
    "    test_df = pd.merge(test_locations, customers, on='customer_id', how='left')\n",
    "    test_df['key'] = 1\n",
    "    vendors['key'] = 1\n",
    "    test_df = pd.merge(test_df, vendors, on='key').drop('key', axis=1)\n",
    "    \n",
    "    test_df.rename(columns={\n",
    "        'latitude_x': 'customer_lat', 'longitude_x': 'customer_lon', 'latitude_y': 'vendor_lat', \n",
    "        'longitude_y': 'vendor_lon', 'status_y': 'vendor_status', 'vendor_rating': 'overall_vendor_rating',\n",
    "        'created_at_x': 'customer_created_at'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    print(f\"‚úÖ Test set created with {len(test_df)} potential recommendations.\")\n",
    "    return test_df\n",
    "\n",
    "print(\"Feature engineering and test set functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe7cfdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Modeling Datasets ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22172/2239096428.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['customer_age'].fillna(df['customer_age'].median(), inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['customer_tenure_days'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['distance'].fillna(df['distance'].median(), inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['customer_tenure_days'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['distance'].fillna(df['distance'].median(), inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['vendor_tag_count'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['customer_age'].fillna(df['customer_age'].median(), inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['customer_tenure_days'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['distance'].fillna(df['distance'].median(), inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['vendor_tag_count'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['vendor_tag_count'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['customer_age'].fillna(df['customer_age'].median(), inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['customer_tenure_days'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['distance'].fillna(df['distance'].median(), inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['vendor_tag_count'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating test set from training data...\n",
      "\n",
      "Creating negative samples...\n",
      "Full training dataset created with 412400 rows.\n",
      "Full training dataset created with 412400 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22172/2239096428.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['customer_age'].fillna(df['customer_age'].median(), inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['customer_tenure_days'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['distance'].fillna(df['distance'].median(), inplace=True)\n",
      "/tmp/ipykernel_22172/2239096428.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['vendor_tag_count'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Creating Modeling Datasets ---\")\n",
    "\n",
    "# Use the merged training data from previous cell\n",
    "train_df = final_training_df.copy()\n",
    "\n",
    "# Apply feature engineering to the positive samples\n",
    "train_df = feature_engineer(train_df)\n",
    "\n",
    "# Since we don't have test data, create a simple test set from training data\n",
    "print(\"\\nCreating test set from training data...\")\n",
    "test_df = train_df.sample(n=min(1000, len(train_df)), random_state=42).copy()\n",
    "test_df = feature_engineer(test_df)\n",
    "\n",
    "# Create Negative Samples\n",
    "print(\"\\nCreating negative samples...\")\n",
    "existing_pairs = set(zip(train_df['customer_id'], train_df['vendor_id']))\n",
    "all_customers = train_customers['customer_id'].unique()\n",
    "all_vendors = vendors['id'].unique()\n",
    "\n",
    "negative_samples = []\n",
    "num_negative_samples = min(len(train_df), 10000)  # Limit to prevent memory issues\n",
    "attempts = 0\n",
    "max_attempts = num_negative_samples * 10\n",
    "\n",
    "while len(negative_samples) < num_negative_samples and attempts < max_attempts:\n",
    "    c, v = np.random.choice(all_customers), np.random.choice(all_vendors)\n",
    "    if (c, v) not in existing_pairs:\n",
    "        negative_samples.append({'customer_id': c, 'vendor_id': v})\n",
    "    attempts += 1\n",
    "        \n",
    "negative_df = pd.DataFrame(negative_samples)\n",
    "\n",
    "# Merge with customer data\n",
    "negative_df = pd.merge(negative_df, train_customers, on='customer_id', how='left')\n",
    "\n",
    "# Merge with vendor data (need to rename columns first)\n",
    "vendors_for_negative = vendors.copy()\n",
    "vendors_for_negative.rename(columns={\n",
    "    'latitude': 'vendor_lat',\n",
    "    'longitude': 'vendor_lon',\n",
    "    'status': 'vendor_status',\n",
    "    'rating': 'vendor_rating'\n",
    "}, inplace=True)\n",
    "\n",
    "negative_df = pd.merge(negative_df, vendors_for_negative, left_on='vendor_id', right_on='id', how='left')\n",
    "\n",
    "# Merge with location data\n",
    "negative_df = pd.merge(negative_df, train_locations, on='customer_id', how='left')\n",
    "\n",
    "# Apply feature engineering\n",
    "negative_df = feature_engineer(negative_df)\n",
    "\n",
    "# Combine positive (target=1) and negative (target=0) samples\n",
    "train_df['target'] = 1\n",
    "negative_df['target'] = 0\n",
    "\n",
    "# Ensure both DataFrames have the same columns\n",
    "common_columns = list(set(train_df.columns) & set(negative_df.columns))\n",
    "train_df = train_df[common_columns]\n",
    "negative_df = negative_df[common_columns]\n",
    "\n",
    "train_full = pd.concat([train_df, negative_df], ignore_index=True)\n",
    "print(f\"Full training dataset created with {len(train_full)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de10dd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Categorical features encoded.\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [col for col in train_full.columns if train_full[col].dtype == 'object']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in test_df.columns:\n",
    "        le = LabelEncoder()\n",
    "        # Fit on all possible values from both train and test sets\n",
    "        combined_series = pd.concat([train_full[col].astype(str), test_df[col].astype(str)])\n",
    "        le.fit(combined_series)\n",
    "        train_full[col] = le.transform(train_full[col].astype(str))\n",
    "        test_df[col] = le.transform(test_df[col].astype(str))\n",
    "\n",
    "print(\"‚úÖ Categorical features encoded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e7b0d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training the Model ---\n",
      "Training LightGBM model with 17 features...\n",
      "‚úÖ Model training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Training the Model ---\")\n",
    "features_to_drop = [\n",
    "    'CID X LOC_NUM X VENDOR', 'customer_id', 'vendor_id', 'id', 'target', 'dob',\n",
    "    'customer_created_at', 'customer_lat', 'customer_lon', 'vendor_lat', 'vendor_lon'\n",
    "]\n",
    "features = [col for col in train_full.columns if col not in features_to_drop and col in test_df.columns]\n",
    "\n",
    "X_train = train_full[features]\n",
    "y_train = train_full['target']\n",
    "X_test = test_df[features]\n",
    "\n",
    "print(f\"Training LightGBM model with {len(features)} features...\")\n",
    "lgbm_params = {\n",
    "    'objective': 'binary', 'metric': 'auc', 'n_estimators': 1000,\n",
    "    'learning_rate': 0.05, 'feature_fraction': 0.8, 'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1, 'verbose': -1, 'n_jobs': -1, 'seed': 42,\n",
    "}\n",
    "model = lgb.LGBMClassifier(**lgbm_params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b61070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Submission File ---\n",
      "‚úÖ Submission.csv created successfully with 889 recommendations!\n",
      "Sample submissions:\n",
      "       CID X VENDOR  target\n",
      "73803   15594 X 195     195\n",
      "332125   3243 X 855     855\n",
      "125431  10092 X 243     243\n",
      "213706  13520 X 105     105\n",
      "64637   12758 X 113     113\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Generating Submission File ---\")\n",
    "test_predictions = model.predict_proba(X_test)[:, 1]\n",
    "test_df['prediction_prob'] = test_predictions\n",
    "\n",
    "# For each customer-location combination, find the vendor with the highest prediction probability\n",
    "test_df.sort_values('prediction_prob', ascending=False, inplace=True)\n",
    "\n",
    "# Check if LOCATION_NUMBER exists, if not create a default one\n",
    "if 'LOCATION_NUMBER' not in test_df.columns:\n",
    "    print(\"LOCATION_NUMBER not found, creating default location numbers...\")\n",
    "    # Group by customer and assign location numbers\n",
    "    test_df['LOCATION_NUMBER'] = test_df.groupby('customer_id').cumcount() + 1\n",
    "\n",
    "submission = test_df.drop_duplicates(subset=['customer_id', 'LOCATION_NUMBER']).copy()\n",
    "\n",
    "# Format for submission - use available columns\n",
    "if 'id' in submission.columns:\n",
    "    vendor_col = 'id'\n",
    "elif 'vendor_id' in submission.columns:\n",
    "    vendor_col = 'vendor_id'\n",
    "else:\n",
    "    print(\"Warning: No vendor ID column found, using index\")\n",
    "    submission['vendor_id'] = submission.index\n",
    "    vendor_col = 'vendor_id'\n",
    "\n",
    "# Create the correct submission format: CID X LOC_NUM X VENDOR\n",
    "submission['CID X LOC_NUM X VENDOR'] = (submission['customer_id'].astype(str) + ' X ' + \n",
    "                                       submission['LOCATION_NUMBER'].astype(str) + ' X ' + \n",
    "                                       submission[vendor_col].astype(str))\n",
    "submission['target'] = submission[vendor_col]\n",
    "submission_file = submission[['CID X LOC_NUM X VENDOR', 'target']].copy()\n",
    "\n",
    "submission_file.to_csv('submission.csv', index=False)\n",
    "print(f\"‚úÖ Submission.csv created successfully with {len(submission_file)} recommendations!\")\n",
    "print(\"Sample submissions:\")\n",
    "print(submission_file.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb5ceee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üéâ PREDICTIVE RESTAURANT RECOMMENDER MODEL COMPLETE! üéâ\n",
      "============================================================\n",
      "\n",
      "üìä SUMMARY:\n",
      "‚Ä¢ Loaded and merged training data from 4 CSV files\n",
      "‚Ä¢ Created 412,400 training samples (positive + negative)\n",
      "‚Ä¢ Engineered 17 features for the model\n",
      "‚Ä¢ Trained LightGBM classifier with AUC optimization\n",
      "‚Ä¢ Generated 889 restaurant recommendations\n",
      "\n",
      "üìÅ FILES CREATED:\n",
      "‚Ä¢ Train/train_merged.csv - Complete merged training dataset\n",
      "‚Ä¢ submission.csv - Final restaurant recommendations\n",
      "\n",
      "‚úÖ The model is ready to predict restaurant preferences!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üéâ PREDICTIVE RESTAURANT RECOMMENDER MODEL COMPLETE! üéâ\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìä SUMMARY:\")\n",
    "print(f\"‚Ä¢ Loaded and merged training data from 4 CSV files\")\n",
    "print(f\"‚Ä¢ Created {len(train_full):,} training samples (positive + negative)\")\n",
    "print(f\"‚Ä¢ Engineered {len(features)} features for the model\")\n",
    "print(f\"‚Ä¢ Trained LightGBM classifier with AUC optimization\")\n",
    "print(f\"‚Ä¢ Generated {len(submission_file)} restaurant recommendations\")\n",
    "print(\"\\nüìÅ FILES CREATED:\")\n",
    "print(\"‚Ä¢ Train/train_merged.csv - Complete merged training dataset\")\n",
    "print(\"‚Ä¢ submission.csv - Final restaurant recommendations\")\n",
    "print(\"\\n‚úÖ The model is ready to predict restaurant preferences!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
