{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80231c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/codespace/.local/lib/python3.12/site-packages (from lightgbm) (2.3.1)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from lightgbm) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install lightgbm if not already installed\n",
    "%pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56877e42",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c6f34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import optuna\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064487fc",
   "metadata": {},
   "source": [
    "### Loading of the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474b2d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully.\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    train_orders = pd.read_csv('Train/orders.csv', low_memory=False)\n",
    "    train_customers = pd.read_csv('Train/train_customers.csv')\n",
    "    train_locations = pd.read_csv('Train/train_locations.csv')\n",
    "    vendors = pd.read_csv('Train/vendors.csv')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Make sure all CSV files are in the same directory as the script.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c8dcf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Preparing and merging data...\n",
      "Preparing and merging data...\n",
      "\n",
      "Columns in train_merged:\n",
      "['order_id', 'customer_id', 'item_count', 'grand_total', 'payment_mode', 'promo_code', 'vendor_discount_amount', 'promo_code_discount_percentage', 'is_favorite', 'is_rated', 'vendor_rating_x', 'driver_rating', 'deliverydistance', 'preparationtime', 'delivery_time', 'order_accepted_time', 'driver_accepted_time', 'ready_for_pickup_time', 'picked_up_time', 'delivered_time', 'delivery_date', 'vendor_id', 'created_at_x', 'LOCATION_NUMBER', 'LOCATION_TYPE', 'CID X LOC_NUM X VENDOR', 'gender', 'dob', 'status', 'verified_x', 'language_x', 'created_at_y', 'updated_at_x', 'id', 'authentication_id', 'vendor_lat', 'vendor_lon', 'vendor_category_en', 'vendor_category_id', 'delivery_charge', 'serving_distance', 'is_open', 'OpeningTime', 'OpeningTime2', 'prepration_time', 'commission', 'is_haked_delivering', 'discount_percentage', 'vendor_status', 'verified_y', 'rank', 'language_y', 'vendor_rating_y', 'sunday_from_time1', 'sunday_to_time1', 'sunday_from_time2', 'sunday_to_time2', 'monday_from_time1', 'monday_to_time1', 'monday_from_time2', 'monday_to_time2', 'tuesday_from_time1', 'tuesday_to_time1', 'tuesday_from_time2', 'tuesday_to_time2', 'wednesday_from_time1', 'wednesday_to_time1', 'wednesday_from_time2', 'wednesday_to_time2', 'thursday_from_time1', 'thursday_to_time1', 'thursday_from_time2', 'thursday_to_time2', 'friday_from_time1', 'friday_to_time1', 'friday_from_time2', 'friday_to_time2', 'saturday_from_time1', 'saturday_to_time1', 'saturday_from_time2', 'saturday_to_time2', 'primary_tags', 'open_close_flags', 'vendor_tag', 'vendor_tag_name', 'one_click_vendor', 'country_id', 'city_id', 'created_at', 'updated_at_y', 'device_type', 'display_orders', 'location_number', 'location_type', 'customer_lat', 'customer_lon']\n",
      "\n",
      "--- Training Data Ready ---\n",
      "Final training data has 395867 rows and 22 columns.\n",
      "Columns: ['customer_id', 'vendor_id', 'gender', 'dob', 'status', 'created_at_x', 'vendor_category_en', 'delivery_charge', 'serving_distance', 'is_open', 'prepration_time', 'commission', 'discount_percentage', 'vendor_status', 'rank', 'vendor_tag_name', 'is_favorite', 'LOCATION_TYPE', 'customer_lat', 'customer_lon', 'vendor_lat', 'vendor_lon']\n",
      "\n",
      "Sample of the final training data:\n",
      "  customer_id  vendor_id gender  dob  status   created_at_x  \\\n",
      "0     KL09J9N         84   Male  NaN     1.0  8/2/2024 5:33   \n",
      "1     KL09J9N         84   Male  NaN     1.0  8/2/2024 5:33   \n",
      "2     KL09J9N         84   Male  NaN     1.0  8/2/2024 5:33   \n",
      "3     KL09J9N         84   Male  NaN     1.0  8/2/2024 5:33   \n",
      "4     H5LGGFX         78   Male  NaN     1.0  8/2/2024 5:34   \n",
      "\n",
      "  vendor_category_en  delivery_charge  serving_distance  is_open  ...  \\\n",
      "0        Restaurants              0.0                15        1  ...   \n",
      "1        Restaurants              0.0                15        1  ...   \n",
      "2        Restaurants              0.0                15        1  ...   \n",
      "3        Restaurants              0.0                15        1  ...   \n",
      "4        Restaurants              0.7                15        0  ...   \n",
      "\n",
      "   discount_percentage  vendor_status  rank  \\\n",
      "0                    0              1    11   \n",
      "1                    0              1    11   \n",
      "2                    0              1    11   \n",
      "3                    0              1    11   \n",
      "4                    0              0    11   \n",
      "\n",
      "                                     vendor_tag_name  is_favorite  \\\n",
      "0                   Burgers,Fries,Kids meal,Shawarma          NaN   \n",
      "1                   Burgers,Fries,Kids meal,Shawarma          NaN   \n",
      "2                   Burgers,Fries,Kids meal,Shawarma          NaN   \n",
      "3                   Burgers,Fries,Kids meal,Shawarma          NaN   \n",
      "4  Pizzas,Italian,Breakfast,Soups,Pasta,Salads,De...          NaN   \n",
      "\n",
      "  LOCATION_TYPE customer_lat customer_lon  vendor_lat  vendor_lon  \n",
      "0          Work    -0.090650   -78.580196   -1.004923    0.078736  \n",
      "1          Work    -0.676098   -78.511007   -1.004923    0.078736  \n",
      "2          Work   -96.407541    43.557974   -1.004923    0.078736  \n",
      "3          Work    -0.089966     0.874226   -1.004923    0.078736  \n",
      "4          Home     1.733950   -78.795830   -0.555404    0.196336  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Columns in train_merged:\n",
      "['order_id', 'customer_id', 'item_count', 'grand_total', 'payment_mode', 'promo_code', 'vendor_discount_amount', 'promo_code_discount_percentage', 'is_favorite', 'is_rated', 'vendor_rating_x', 'driver_rating', 'deliverydistance', 'preparationtime', 'delivery_time', 'order_accepted_time', 'driver_accepted_time', 'ready_for_pickup_time', 'picked_up_time', 'delivered_time', 'delivery_date', 'vendor_id', 'created_at_x', 'LOCATION_NUMBER', 'LOCATION_TYPE', 'CID X LOC_NUM X VENDOR', 'gender', 'dob', 'status', 'verified_x', 'language_x', 'created_at_y', 'updated_at_x', 'id', 'authentication_id', 'vendor_lat', 'vendor_lon', 'vendor_category_en', 'vendor_category_id', 'delivery_charge', 'serving_distance', 'is_open', 'OpeningTime', 'OpeningTime2', 'prepration_time', 'commission', 'is_haked_delivering', 'discount_percentage', 'vendor_status', 'verified_y', 'rank', 'language_y', 'vendor_rating_y', 'sunday_from_time1', 'sunday_to_time1', 'sunday_from_time2', 'sunday_to_time2', 'monday_from_time1', 'monday_to_time1', 'monday_from_time2', 'monday_to_time2', 'tuesday_from_time1', 'tuesday_to_time1', 'tuesday_from_time2', 'tuesday_to_time2', 'wednesday_from_time1', 'wednesday_to_time1', 'wednesday_from_time2', 'wednesday_to_time2', 'thursday_from_time1', 'thursday_to_time1', 'thursday_from_time2', 'thursday_to_time2', 'friday_from_time1', 'friday_to_time1', 'friday_from_time2', 'friday_to_time2', 'saturday_from_time1', 'saturday_to_time1', 'saturday_from_time2', 'saturday_to_time2', 'primary_tags', 'open_close_flags', 'vendor_tag', 'vendor_tag_name', 'one_click_vendor', 'country_id', 'city_id', 'created_at', 'updated_at_y', 'device_type', 'display_orders', 'location_number', 'location_type', 'customer_lat', 'customer_lon']\n",
      "\n",
      "--- Training Data Ready ---\n",
      "Final training data has 395867 rows and 22 columns.\n",
      "Columns: ['customer_id', 'vendor_id', 'gender', 'dob', 'status', 'created_at_x', 'vendor_category_en', 'delivery_charge', 'serving_distance', 'is_open', 'prepration_time', 'commission', 'discount_percentage', 'vendor_status', 'rank', 'vendor_tag_name', 'is_favorite', 'LOCATION_TYPE', 'customer_lat', 'customer_lon', 'vendor_lat', 'vendor_lon']\n",
      "\n",
      "Sample of the final training data:\n",
      "  customer_id  vendor_id gender  dob  status   created_at_x  \\\n",
      "0     KL09J9N         84   Male  NaN     1.0  8/2/2024 5:33   \n",
      "1     KL09J9N         84   Male  NaN     1.0  8/2/2024 5:33   \n",
      "2     KL09J9N         84   Male  NaN     1.0  8/2/2024 5:33   \n",
      "3     KL09J9N         84   Male  NaN     1.0  8/2/2024 5:33   \n",
      "4     H5LGGFX         78   Male  NaN     1.0  8/2/2024 5:34   \n",
      "\n",
      "  vendor_category_en  delivery_charge  serving_distance  is_open  ...  \\\n",
      "0        Restaurants              0.0                15        1  ...   \n",
      "1        Restaurants              0.0                15        1  ...   \n",
      "2        Restaurants              0.0                15        1  ...   \n",
      "3        Restaurants              0.0                15        1  ...   \n",
      "4        Restaurants              0.7                15        0  ...   \n",
      "\n",
      "   discount_percentage  vendor_status  rank  \\\n",
      "0                    0              1    11   \n",
      "1                    0              1    11   \n",
      "2                    0              1    11   \n",
      "3                    0              1    11   \n",
      "4                    0              0    11   \n",
      "\n",
      "                                     vendor_tag_name  is_favorite  \\\n",
      "0                   Burgers,Fries,Kids meal,Shawarma          NaN   \n",
      "1                   Burgers,Fries,Kids meal,Shawarma          NaN   \n",
      "2                   Burgers,Fries,Kids meal,Shawarma          NaN   \n",
      "3                   Burgers,Fries,Kids meal,Shawarma          NaN   \n",
      "4  Pizzas,Italian,Breakfast,Soups,Pasta,Salads,De...          NaN   \n",
      "\n",
      "  LOCATION_TYPE customer_lat customer_lon  vendor_lat  vendor_lon  \n",
      "0          Work    -0.090650   -78.580196   -1.004923    0.078736  \n",
      "1          Work    -0.676098   -78.511007   -1.004923    0.078736  \n",
      "2          Work   -96.407541    43.557974   -1.004923    0.078736  \n",
      "3          Work    -0.089966     0.874226   -1.004923    0.078736  \n",
      "4          Home     1.733950   -78.795830   -0.555404    0.196336  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Merged training data saved to Train/train_merged.csv\n",
      "\n",
      "Merged training data saved to Train/train_merged.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "\n",
    "try:\n",
    "    # --- Load all source files ---\n",
    "    train_orders = pd.read_csv('Train/orders.csv')\n",
    "    train_customers = pd.read_csv('Train/train_customers.csv')\n",
    "    train_locations = pd.read_csv('Train/train_locations.csv')\n",
    "    vendors = pd.read_csv('Train/vendors.csv')\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    print(\"Please ensure all CSV files are in the correct 'Train/' subdirectory.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Preparing and merging data...\")\n",
    "\n",
    "# --- Rename columns BEFORE merging to avoid confusion ('_x', '_y') ---\n",
    "vendors.rename(columns={\n",
    "    'latitude': 'vendor_lat',\n",
    "    'longitude': 'vendor_lon',\n",
    "    'status': 'vendor_status',\n",
    "    'rating': 'vendor_rating'\n",
    "}, inplace=True)\n",
    "\n",
    "train_locations.rename(columns={\n",
    "    'latitude': 'customer_lat',\n",
    "    'longitude': 'customer_lon'\n",
    "}, inplace=True)\n",
    "\n",
    "# --- Merge all training data sources ---\n",
    "# Start with orders and add details about the customer, vendor, and location\n",
    "train_merged = train_orders.merge(train_customers, on='customer_id', how='left')\n",
    "train_merged = train_merged.merge(vendors, left_on='vendor_id', right_on='id', how='left')\n",
    "train_merged = train_merged.merge(\n",
    "    train_locations,\n",
    "    on=['customer_id'],  # Only merge on customer_id\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Debug: print columns to check for missing/misnamed columns\n",
    "print(\"\\nColumns in train_merged:\")\n",
    "print(train_merged.columns.tolist())\n",
    "\n",
    "# --- Define the specific columns required for training a model ---\n",
    "# These features are known at the time of prediction and avoid data leakage\n",
    "required_columns = [\n",
    "    # --- IDs (for context, not as model features) ---\n",
    "    'customer_id',\n",
    "    'vendor_id',\n",
    "    # 'LOCATION_NUMBER',  # Remove if not present\n",
    "\n",
    "    # --- Customer Features ---\n",
    "    'gender',\n",
    "    'dob',                         # To calculate customer age\n",
    "    'status',                      # Customer account status\n",
    "    'created_at_x',                # To calculate customer tenure (from customers table)\n",
    "\n",
    "    # --- Vendor Features ---\n",
    "    'vendor_category_en',\n",
    "    'delivery_charge',\n",
    "    'serving_distance',\n",
    "    'is_open',\n",
    "    'prepration_time',             # Vendor's average preparation time\n",
    "    'commission',\n",
    "    'discount_percentage',\n",
    "    'vendor_status',               # Vendor's account status\n",
    "    'rank',\n",
    "    # 'vendor_rating',               # Vendor's overall historical rating (removed)\n",
    "    'vendor_tag_name',             # Descriptive tags like 'Healthy', 'Pizza'\n",
    "\n",
    "    # --- Location & Interaction Features ---\n",
    "    'is_favorite',                 # If the customer has favorited this vendor\n",
    "    'LOCATION_TYPE',               # e.g., 'Home', 'Work'\n",
    "    'customer_lat',\n",
    "    'customer_lon',\n",
    "    'vendor_lat',\n",
    "    'vendor_lon',\n",
    "]\n",
    "\n",
    "# --- Create the final training dataframe with only the required columns ---\n",
    "# Keep all rows, even those with missing values\n",
    "final_training_df = train_merged[required_columns].reset_index(drop=True)\n",
    "\n",
    "print(\"\\n--- Training Data Ready ---\")\n",
    "print(f\"Final training data has {final_training_df.shape[0]} rows and {final_training_df.shape[1]} columns.\")\n",
    "print(\"Columns:\", final_training_df.columns.tolist())\n",
    "print(\"\\nSample of the final training data:\")\n",
    "print(final_training_df.head())\n",
    "\n",
    "# Save the final DataFrame to CSV\n",
    "final_training_df.to_csv('Train/train_merged.csv', index=False)\n",
    "print(\"\\nMerged training data saved to Train/train_merged.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c71514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering and test set functions defined.\n"
     ]
    }
   ],
   "source": [
    "def feature_engineer(df):\n",
    "    \"\"\"Creates new, predictive features from existing columns.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    if 'dob' in df.columns:\n",
    "        df['customer_age'] = 2025 - pd.to_numeric(df['dob'], errors='coerce')\n",
    "        df['customer_age'].fillna(df['customer_age'].median(), inplace=True)\n",
    "    \n",
    "    if 'created_at_x' in df.columns:\n",
    "        try:\n",
    "            df['customer_tenure_days'] = (datetime(2025, 7, 28) - pd.to_datetime(df['created_at_x'], errors='coerce')).dt.days\n",
    "            df['customer_tenure_days'].fillna(0, inplace=True)\n",
    "        except:\n",
    "            df['customer_tenure_days'] = 0\n",
    "    \n",
    "    if 'customer_lat' in df.columns and 'vendor_lat' in df.columns:\n",
    "        df['distance'] = np.sqrt((df['customer_lat'] - df['vendor_lat'])**2 + (df['customer_lon'] - df['vendor_lon'])**2)\n",
    "        df['distance'].fillna(df['distance'].median(), inplace=True)\n",
    "    \n",
    "    if 'vendor_tag_name' in df.columns:\n",
    "        df['vendor_tag_count'] = df['vendor_tag_name'].fillna('').astype(str).str.count(',') + 1\n",
    "        df['vendor_tag_count'].fillna(0, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_test_set(data_path='Test/'):\n",
    "    \"\"\"Loads and prepares the test data by creating all possible recommendations.\"\"\"\n",
    "    print(\"\\nPreparing test set...\")\n",
    "    try:\n",
    "        test_locations = pd.read_csv(f'{data_path}test_locations.csv')\n",
    "        customers = pd.read_csv('Train/train_customers.csv')\n",
    "        vendors = pd.read_csv('Train/vendors.csv')\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        print(\"Creating mock test set from training data...\")\n",
    "        # Create a mock test set from existing data\n",
    "        customers = pd.read_csv('Train/train_customers.csv')\n",
    "        vendors = pd.read_csv('Train/vendors.csv')\n",
    "        locations = pd.read_csv('Train/train_locations.csv')\n",
    "        \n",
    "        # Sample some customers and locations for testing\n",
    "        test_customers = customers.sample(n=min(100, len(customers)), random_state=42)\n",
    "        test_locations = locations[locations['customer_id'].isin(test_customers['customer_id'])].copy()\n",
    "        \n",
    "        test_df = pd.merge(test_locations, test_customers, on='customer_id', how='left')\n",
    "        test_df['key'] = 1\n",
    "        vendors['key'] = 1\n",
    "        test_df = pd.merge(test_df, vendors, on='key').drop('key', axis=1)\n",
    "        \n",
    "        test_df.rename(columns={\n",
    "            'latitude_x': 'customer_lat', 'longitude_x': 'customer_lon', \n",
    "            'latitude_y': 'vendor_lat', 'longitude_y': 'vendor_lon', \n",
    "            'status_y': 'vendor_status'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        print(f\"âœ… Mock test set created with {len(test_df)} potential recommendations.\")\n",
    "        return test_df\n",
    "    \n",
    "    test_df = pd.merge(test_locations, customers, on='customer_id', how='left')\n",
    "    test_df['key'] = 1\n",
    "    vendors['key'] = 1\n",
    "    test_df = pd.merge(test_df, vendors, on='key').drop('key', axis=1)\n",
    "    \n",
    "    test_df.rename(columns={\n",
    "        'latitude_x': 'customer_lat', 'longitude_x': 'customer_lon', 'latitude_y': 'vendor_lat', \n",
    "        'longitude_y': 'vendor_lon', 'status_y': 'vendor_status', 'vendor_rating': 'overall_vendor_rating',\n",
    "        'created_at_x': 'customer_created_at'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    print(f\"âœ… Test set created with {len(test_df)} potential recommendations.\")\n",
    "    return test_df\n",
    "\n",
    "print(\"Feature engineering and test set functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3be991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Advanced feature engineering functions defined!\n"
     ]
    }
   ],
   "source": [
    "def create_advanced_features(train_orders, train_customers, vendors, train_locations):\n",
    "    \"\"\"\n",
    "    Create advanced customer-centric, vendor-centric, and interaction features\n",
    "    that significantly improve model performance.\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ Creating Advanced Features...\")\n",
    "    \n",
    "    # Create a clean copy of the data\n",
    "    orders_clean = train_orders.copy()\n",
    "    \n",
    "    # Clean and convert data types\n",
    "    print(\"ðŸ§¹ Cleaning data types...\")\n",
    "    orders_clean['delivery_date'] = pd.to_datetime(orders_clean['delivery_date'], errors='coerce')\n",
    "    orders_clean['grand_total'] = pd.to_numeric(orders_clean['grand_total'], errors='coerce')\n",
    "    orders_clean['item_count'] = pd.to_numeric(orders_clean['item_count'], errors='coerce')\n",
    "    orders_clean['vendor_rating'] = pd.to_numeric(orders_clean['vendor_rating'], errors='coerce')\n",
    "    orders_clean['preparationtime'] = pd.to_numeric(orders_clean['preparationtime'], errors='coerce')\n",
    "    orders_clean['delivery_time'] = pd.to_numeric(orders_clean['delivery_time'], errors='coerce')\n",
    "    \n",
    "    # Drop rows with invalid dates or amounts\n",
    "    initial_len = len(orders_clean)\n",
    "    orders_clean = orders_clean.dropna(subset=['delivery_date', 'grand_total', 'customer_id', 'vendor_id'])\n",
    "    print(f\"Cleaned data: {initial_len} -> {len(orders_clean)} rows\")\n",
    "    \n",
    "    # ===== CUSTOMER-CENTRIC FEATURES =====\n",
    "    print(\"ðŸ“Š Creating customer-centric features...\")\n",
    "    \n",
    "    # Order Statistics\n",
    "    customer_stats = orders_clean.groupby('customer_id').agg({\n",
    "        'grand_total': ['mean', 'std', 'sum', 'count'],\n",
    "        'item_count': ['mean', 'sum'],\n",
    "        'vendor_id': 'nunique',  # Number of unique vendors they've ordered from\n",
    "        'delivery_date': ['min', 'max'],  # First and last order dates\n",
    "        'is_rated': 'mean'  # Rating engagement rate\n",
    "    }).round(4)\n",
    "    \n",
    "    # Flatten column names\n",
    "    customer_stats.columns = [\n",
    "        'customer_avg_order_value', 'customer_order_value_std', 'customer_total_spent',\n",
    "        'customer_total_orders', 'customer_avg_items_per_order', 'customer_total_items',\n",
    "        'customer_unique_vendors', 'customer_first_order', 'customer_last_order',\n",
    "        'customer_rating_engagement'\n",
    "    ]\n",
    "    \n",
    "    # Time-based features\n",
    "    customer_stats['days_since_first_order'] = (datetime.now() - customer_stats['customer_first_order']).dt.days\n",
    "    customer_stats['customer_lifetime_days'] = (customer_stats['customer_last_order'] - customer_stats['customer_first_order']).dt.days\n",
    "    \n",
    "    # Order frequency (handle division by zero)\n",
    "    customer_stats['customer_order_frequency'] = customer_stats['customer_total_orders'] / np.maximum(customer_stats['customer_lifetime_days'], 1)\n",
    "    customer_stats['avg_days_between_orders'] = np.maximum(customer_stats['customer_lifetime_days'], 1) / customer_stats['customer_total_orders']\n",
    "    \n",
    "    customer_stats = customer_stats.reset_index().fillna(0)\n",
    "    \n",
    "    # ===== VENDOR-CENTRIC FEATURES =====\n",
    "    print(\"ðŸª Creating vendor-centric features...\")\n",
    "    \n",
    "    vendor_stats = orders_clean.groupby('vendor_id').agg({\n",
    "        'customer_id': 'nunique',  # Unique customers\n",
    "        'order_id': 'count',       # Total orders\n",
    "        'grand_total': 'mean',     # Average order value\n",
    "        'item_count': 'mean',      # Average items per order\n",
    "        'is_favorite': 'mean',     # How often they're favorited\n",
    "        'vendor_rating': 'mean',   # Average rating\n",
    "        'preparationtime': 'mean', # Average prep time\n",
    "        'delivery_time': 'mean'    # Average delivery time\n",
    "    }).round(4)\n",
    "    \n",
    "    vendor_stats.columns = [\n",
    "        'vendor_unique_customers', 'vendor_total_orders', 'vendor_avg_order_value',\n",
    "        'vendor_avg_items_per_order', 'vendor_favorite_ratio', 'vendor_avg_rating',\n",
    "        'vendor_avg_prep_time', 'vendor_avg_delivery_time'\n",
    "    ]\n",
    "    \n",
    "    vendor_stats = vendor_stats.reset_index().fillna(0)\n",
    "    \n",
    "    # ===== CUSTOMER-VENDOR INTERACTION FEATURES =====\n",
    "    print(\"ðŸ¤ Creating customer-vendor interaction features...\")\n",
    "    \n",
    "    # For each customer-vendor pair, calculate interaction history\n",
    "    interaction_stats = orders_clean.groupby(['customer_id', 'vendor_id']).agg({\n",
    "        'order_id': 'count',           # How many times this customer ordered from this vendor\n",
    "        'grand_total': 'mean',         # Average spend at this vendor\n",
    "        'is_favorite': 'max',          # Has this customer favorited this vendor\n",
    "        'vendor_rating': 'mean',       # Average rating given to this vendor\n",
    "        'delivery_date': 'max'         # Last order date from this vendor\n",
    "    }).round(4)\n",
    "    \n",
    "    interaction_stats.columns = [\n",
    "        'customer_vendor_order_count', 'customer_vendor_avg_spend',\n",
    "        'customer_vendor_is_favorite', 'customer_vendor_avg_rating',\n",
    "        'customer_vendor_last_order'\n",
    "    ]\n",
    "    \n",
    "    # Days since last order from this vendor\n",
    "    interaction_stats['days_since_last_order_from_vendor'] = (datetime.now() - interaction_stats['customer_vendor_last_order']).dt.days\n",
    "    \n",
    "    interaction_stats = interaction_stats.reset_index().fillna(0)\n",
    "    \n",
    "    # ===== CUSTOMER PREFERENCES =====\n",
    "    print(\"â¤ï¸ Creating customer preference features...\")\n",
    "    \n",
    "    # Most popular vendor category for each customer\n",
    "    customer_vendor_category = orders_clean.merge(vendors[['id', 'vendor_category_en']], \n",
    "                                                   left_on='vendor_id', right_on='id', how='left')\n",
    "    \n",
    "    customer_fav_category = customer_vendor_category.groupby(['customer_id', 'vendor_category_en']).size().reset_index(name='orders_in_category')\n",
    "    customer_fav_category = customer_fav_category.loc[customer_fav_category.groupby('customer_id')['orders_in_category'].idxmax()]\n",
    "    customer_fav_category = customer_fav_category[['customer_id', 'vendor_category_en']].rename(columns={'vendor_category_en': 'customer_favorite_category'})\n",
    "    \n",
    "    # Additional time-based features\n",
    "    print(\"â° Creating time-based features...\")\n",
    "    \n",
    "    # Extract time features\n",
    "    orders_clean['hour_of_day'] = orders_clean['delivery_date'].dt.hour\n",
    "    orders_clean['day_of_week'] = orders_clean['delivery_date'].dt.dayofweek\n",
    "    orders_clean['is_weekend'] = orders_clean['day_of_week'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    # Customer time preferences\n",
    "    customer_time_prefs = orders_clean.groupby('customer_id').agg({\n",
    "        'hour_of_day': 'mean',\n",
    "        'is_weekend': 'mean'\n",
    "    }).round(4)\n",
    "    \n",
    "    customer_time_prefs.columns = ['customer_avg_order_hour', 'customer_weekend_ratio']\n",
    "    customer_time_prefs = customer_time_prefs.reset_index()\n",
    "    \n",
    "    # Merge time preferences with customer stats\n",
    "    customer_stats = customer_stats.merge(customer_time_prefs, on='customer_id', how='left')\n",
    "    \n",
    "    print(f\"âœ… Created features for {len(customer_stats)} customers, {len(vendor_stats)} vendors\")\n",
    "    print(f\"âœ… Created {len(interaction_stats)} customer-vendor interaction records\")\n",
    "    \n",
    "    return customer_stats, vendor_stats, interaction_stats, customer_fav_category\n",
    "\n",
    "def merge_advanced_features(df, customer_stats, vendor_stats, interaction_stats, customer_fav_category):\n",
    "    \"\"\"\n",
    "    Merge all advanced features into the main dataframe\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”„ Merging advanced features...\")\n",
    "    \n",
    "    # Merge customer features\n",
    "    df = df.merge(customer_stats, on='customer_id', how='left')\n",
    "    \n",
    "    # Merge vendor features  \n",
    "    df = df.merge(vendor_stats, on='vendor_id', how='left')\n",
    "    \n",
    "    # Merge interaction features\n",
    "    df = df.merge(interaction_stats, on=['customer_id', 'vendor_id'], how='left')\n",
    "    \n",
    "    # Merge customer preferences\n",
    "    df = df.merge(customer_fav_category, on='customer_id', how='left')\n",
    "    \n",
    "    # Fill missing values for customers/vendors not in training data\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(0)\n",
    "    \n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    df[categorical_cols] = df[categorical_cols].fillna('unknown')\n",
    "    \n",
    "    print(f\"âœ… Final dataset shape: {df.shape}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"ðŸŽ¯ Advanced feature engineering functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18b7969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Cross-validation and hyperparameter optimization functions defined!\n"
     ]
    }
   ],
   "source": [
    "def cross_validate_model(X, y, params, n_folds=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform stratified k-fold cross-validation to get robust performance estimates\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ”„ Performing {n_folds}-fold cross-validation...\")\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    cv_scores = []\n",
    "    models = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        print(f\"  ðŸ“Š Training fold {fold + 1}/{n_folds}...\")\n",
    "        \n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Train model with regularization to prevent overfitting\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=[(X_val_fold, y_val_fold)],\n",
    "            eval_metric='auc',\n",
    "            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]  # Reduced early stopping rounds\n",
    "        )\n",
    "        \n",
    "        # Predict and score\n",
    "        y_pred = model.predict_proba(X_val_fold)[:, 1]\n",
    "        score = roc_auc_score(y_val_fold, y_pred)\n",
    "        cv_scores.append(score)\n",
    "        models.append(model)\n",
    "        \n",
    "        print(f\"    âœ… Fold {fold + 1} AUC: {score:.4f}\")\n",
    "    \n",
    "    print(f\"ðŸŽ¯ Cross-validation results:\")\n",
    "    print(f\"  â€¢ Mean AUC: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores) * 2:.4f})\")\n",
    "    print(f\"  â€¢ Individual folds: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "    \n",
    "    return np.mean(cv_scores), models\n",
    "\n",
    "def optimize_hyperparameters(X, y, n_trials=30, random_state=42):\n",
    "    \"\"\"\n",
    "    Use Optuna to find the best hyperparameters for LightGBM\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ” Optimizing hyperparameters with {n_trials} trials...\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        # Define hyperparameter search space with more conservative values\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'verbose': -1,\n",
    "            'random_state': random_state,\n",
    "            'n_jobs': -1,\n",
    "            \n",
    "            # Regularization parameters to prevent overfitting\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 800),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 10, 50),  # Reduced to prevent overfitting\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 0.9),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 0.9),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 20, 200),  # Increased for regularization\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 2.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 2.0),\n",
    "            'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0)\n",
    "        }\n",
    "        \n",
    "        # Use 3-fold CV for speed during optimization\n",
    "        cv_score, _ = cross_validate_model(X, y, params, n_folds=3, random_state=random_state)\n",
    "        return cv_score\n",
    "    \n",
    "    # Run optimization (removed random_state from create_study)\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    print(f\"ðŸ† Best hyperparameters found:\")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"  â€¢ {key}: {value}\")\n",
    "    print(f\"ðŸŽ¯ Best CV AUC: {study.best_trial.value:.4f}\")\n",
    "    \n",
    "    return study.best_trial.params\n",
    "\n",
    "def train_ensemble_model(X, y, params, n_folds=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Train an ensemble of models using cross-validation and return averaged predictions\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ Training ensemble model...\")\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    models = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        print(f\"  ðŸ“Š Training ensemble model {fold + 1}/{n_folds}...\")\n",
    "        \n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=[(X_val_fold, y_val_fold)],\n",
    "            eval_metric='auc',\n",
    "            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        models.append(model)\n",
    "    \n",
    "    print(f\"âœ… Ensemble of {len(models)} models trained successfully!\")\n",
    "    return models\n",
    "\n",
    "def predict_with_ensemble(models, X_test):\n",
    "    \"\"\"\n",
    "    Make predictions using ensemble of models and return averaged probabilities\n",
    "    \"\"\"\n",
    "    predictions = np.zeros(len(X_test))\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        pred = model.predict_proba(X_test)[:, 1]\n",
    "        predictions += pred\n",
    "    \n",
    "    # Average the predictions\n",
    "    predictions /= len(models)\n",
    "    return predictions\n",
    "\n",
    "print(\"ðŸŽ¯ Cross-validation and hyperparameter optimization functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe7cfdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸš€ ENHANCED TRAINING DATASET WITH ROBUST FEATURES\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ¯ STEP 1: Creating Robust Advanced Features\n",
      "Data cleaned: 135303 rows\n",
      "ðŸ“Š Creating customer features...\n",
      "ðŸª Creating vendor features...\n",
      "ðŸ¤ Creating interaction features...\n",
      "âœ… Customer features: 27445 customers\n",
      "âœ… Vendor features: 100 vendors\n",
      "âœ… Interaction features: 71484 customer-vendor pairs\n",
      "\n",
      "ðŸŽ¯ STEP 2: Creating Customer-Vendor Combinations\n",
      "Found 34523 unique customers and 100 unique vendors\n",
      "Selected 2000 customers and 50 vendors\n",
      "Created 100000 combinations\n",
      "\n",
      "ðŸŽ¯ STEP 3: Adding Target Labels\n",
      "Selected 2000 customers and 50 vendors\n",
      "Created 100000 combinations\n",
      "\n",
      "ðŸŽ¯ STEP 3: Adding Target Labels\n",
      "Positive examples: 1,650\n",
      "Negative examples: 98,350\n",
      "Positive ratio: 0.0165\n",
      "\n",
      "ðŸŽ¯ STEP 4: Merging Features\n",
      "Positive examples: 1,650\n",
      "Negative examples: 98,350\n",
      "Positive ratio: 0.0165\n",
      "\n",
      "ðŸŽ¯ STEP 4: Merging Features\n",
      "\n",
      "âœ… ENHANCED TRAINING DATASET COMPLETE!\n",
      "ðŸ“Š Final dataset: 151,400 rows Ã— 92 features\n",
      "ðŸ“Š Positive ratio: 0.0296\n",
      "âœ… Test set: 15,000 rows\n",
      "================================================================================\n",
      "\n",
      "âœ… ENHANCED TRAINING DATASET COMPLETE!\n",
      "ðŸ“Š Final dataset: 151,400 rows Ã— 92 features\n",
      "ðŸ“Š Positive ratio: 0.0296\n",
      "âœ… Test set: 15,000 rows\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ðŸš€ ENHANCED TRAINING DATASET WITH ROBUST FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Step 1: Create simplified but robust advanced features\n",
    "print(\"\\nðŸŽ¯ STEP 1: Creating Robust Advanced Features\")\n",
    "\n",
    "# Clean the data first\n",
    "orders_clean = train_orders.copy()\n",
    "\n",
    "# Convert numeric columns properly\n",
    "numeric_cols = ['grand_total', 'item_count', 'vendor_rating', 'preparationtime', 'delivery_time']\n",
    "for col in numeric_cols:\n",
    "    if col in orders_clean.columns:\n",
    "        orders_clean[col] = pd.to_numeric(orders_clean[col], errors='coerce')\n",
    "\n",
    "# Convert binary columns\n",
    "binary_cols = ['is_favorite', 'is_rated']\n",
    "for col in binary_cols:\n",
    "    if col in orders_clean.columns:\n",
    "        orders_clean[col] = orders_clean[col].map({'Yes': 1, 'No': 0, 1: 1, 0: 0}).fillna(0)\n",
    "\n",
    "print(f\"Data cleaned: {len(orders_clean)} rows\")\n",
    "\n",
    "# CUSTOMER FEATURES\n",
    "print(\"ðŸ“Š Creating customer features...\")\n",
    "customer_features = orders_clean.groupby('customer_id').agg({\n",
    "    'grand_total': ['count', 'mean', 'sum'],  # order_count, avg_order_value, total_spent\n",
    "    'item_count': 'sum',                      # total_items_ordered\n",
    "    'vendor_id': 'nunique',                   # unique_vendors_used\n",
    "    'is_favorite': 'mean',                    # favorite_rate\n",
    "    'is_rated': 'mean'                        # rating_rate\n",
    "}).round(4)\n",
    "\n",
    "# Flatten column names\n",
    "customer_features.columns = ['customer_total_orders', 'customer_avg_order_value', 'customer_total_spent',\n",
    "                           'customer_total_items', 'customer_unique_vendors', 'customer_favorite_rate', 'customer_rating_rate']\n",
    "customer_features = customer_features.reset_index()\n",
    "\n",
    "# VENDOR FEATURES  \n",
    "print(\"ðŸª Creating vendor features...\")\n",
    "vendor_features = orders_clean.groupby('vendor_id').agg({\n",
    "    'customer_id': 'nunique',     # unique_customers\n",
    "    'order_id': 'count',          # total_orders\n",
    "    'grand_total': 'mean',        # avg_order_value\n",
    "    'is_favorite': 'mean',        # favorite_rate\n",
    "    'vendor_rating': 'mean'       # avg_rating\n",
    "}).round(4)\n",
    "\n",
    "vendor_features.columns = ['vendor_unique_customers', 'vendor_total_orders', 'vendor_avg_order_value',\n",
    "                         'vendor_favorite_rate', 'vendor_avg_rating']\n",
    "vendor_features = vendor_features.reset_index()\n",
    "\n",
    "# CUSTOMER-VENDOR INTERACTION FEATURES\n",
    "print(\"ðŸ¤ Creating interaction features...\")\n",
    "interaction_features = orders_clean.groupby(['customer_id', 'vendor_id']).agg({\n",
    "    'order_id': 'count',          # times_ordered_from_vendor\n",
    "    'grand_total': 'mean',        # avg_spend_at_vendor\n",
    "    'is_favorite': 'max'          # has_favorited_vendor\n",
    "}).round(4)\n",
    "\n",
    "interaction_features.columns = ['customer_vendor_orders', 'customer_vendor_avg_spend', 'customer_vendor_favorited']\n",
    "interaction_features = interaction_features.reset_index()\n",
    "\n",
    "print(f\"âœ… Customer features: {len(customer_features)} customers\")\n",
    "print(f\"âœ… Vendor features: {len(vendor_features)} vendors\") \n",
    "print(f\"âœ… Interaction features: {len(interaction_features)} customer-vendor pairs\")\n",
    "\n",
    "# Step 2: Create customer-vendor combinations\n",
    "print(\"\\nðŸŽ¯ STEP 2: Creating Customer-Vendor Combinations\")\n",
    "all_customers = train_customers['customer_id'].unique()\n",
    "all_vendors = vendors['id'].unique()\n",
    "\n",
    "print(f\"Found {len(all_customers)} unique customers and {len(all_vendors)} unique vendors\")\n",
    "\n",
    "# Use strategic sampling for better coverage\n",
    "sample_customers = min(2000, len(all_customers))\n",
    "sample_vendors = min(200, len(all_vendors))\n",
    "\n",
    "# Prioritize customers with order history\n",
    "customers_with_orders = customer_features['customer_id'].tolist()\n",
    "customers_without_orders = [c for c in all_customers if c not in customers_with_orders]\n",
    "\n",
    "# Take all customers with orders + sample of those without\n",
    "sampled_customers = customers_with_orders[:sample_customers//2]\n",
    "if len(customers_without_orders) > 0:\n",
    "    sampled_customers.extend(np.random.choice(customers_without_orders, \n",
    "                                            size=min(sample_customers//2, len(customers_without_orders)), \n",
    "                                            replace=False).tolist())\n",
    "\n",
    "# Similar for vendors\n",
    "vendors_with_orders = vendor_features['vendor_id'].tolist()\n",
    "vendors_without_orders = [v for v in all_vendors if v not in vendors_with_orders]\n",
    "\n",
    "sampled_vendors = vendors_with_orders[:sample_vendors//2]\n",
    "if len(vendors_without_orders) > 0:\n",
    "    sampled_vendors.extend(np.random.choice(vendors_without_orders,\n",
    "                                          size=min(sample_vendors//2, len(vendors_without_orders)),\n",
    "                                          replace=False).tolist())\n",
    "\n",
    "print(f\"Selected {len(sampled_customers)} customers and {len(sampled_vendors)} vendors\")\n",
    "\n",
    "# Create combinations\n",
    "combinations = []\n",
    "for customer in sampled_customers:\n",
    "    for vendor in sampled_vendors:\n",
    "        combinations.append({'customer_id': customer, 'vendor_id': vendor})\n",
    "\n",
    "train_full = pd.DataFrame(combinations)\n",
    "print(f\"Created {len(train_full)} combinations\")\n",
    "\n",
    "# Step 3: Add target labels\n",
    "print(\"\\nðŸŽ¯ STEP 3: Adding Target Labels\")\n",
    "actual_orders = set(zip(orders_clean['customer_id'], orders_clean['vendor_id']))\n",
    "train_full['target'] = train_full.apply(\n",
    "    lambda row: 1 if (row['customer_id'], row['vendor_id']) in actual_orders else 0, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"Positive examples: {train_full['target'].sum():,}\")\n",
    "print(f\"Negative examples: {(train_full['target'] == 0).sum():,}\")\n",
    "print(f\"Positive ratio: {train_full['target'].mean():.4f}\")\n",
    "\n",
    "# Step 4: Merge all features\n",
    "print(\"\\nðŸŽ¯ STEP 4: Merging Features\")\n",
    "\n",
    "# Basic customer and vendor data\n",
    "train_full = train_full.merge(train_customers, on='customer_id', how='left')\n",
    "\n",
    "vendors_renamed = vendors.copy()\n",
    "vendors_renamed.rename(columns={'latitude': 'vendor_lat', 'longitude': 'vendor_lon', 'status': 'vendor_status'}, inplace=True)\n",
    "train_full = train_full.merge(vendors_renamed, left_on='vendor_id', right_on='id', how='left')\n",
    "\n",
    "train_full = train_full.merge(train_locations, on='customer_id', how='left')\n",
    "\n",
    "# Advanced features\n",
    "train_full = train_full.merge(customer_features, on='customer_id', how='left')\n",
    "train_full = train_full.merge(vendor_features, on='vendor_id', how='left')\n",
    "train_full = train_full.merge(interaction_features, on=['customer_id', 'vendor_id'], how='left')\n",
    "\n",
    "# Apply basic feature engineering\n",
    "train_full = feature_engineer(train_full)\n",
    "\n",
    "# Fill missing values\n",
    "numeric_cols = train_full.select_dtypes(include=[np.number]).columns\n",
    "train_full[numeric_cols] = train_full[numeric_cols].fillna(0)\n",
    "\n",
    "categorical_cols = train_full.select_dtypes(include=['object']).columns\n",
    "train_full[categorical_cols] = train_full[categorical_cols].fillna('unknown')\n",
    "\n",
    "print(f\"\\nâœ… ENHANCED TRAINING DATASET COMPLETE!\")\n",
    "print(f\"ðŸ“Š Final dataset: {train_full.shape[0]:,} rows Ã— {train_full.shape[1]} features\")\n",
    "print(f\"ðŸ“Š Positive ratio: {train_full['target'].mean():.4f}\")\n",
    "\n",
    "# Create test set\n",
    "test_df = train_full.sample(n=min(15000, len(train_full)), random_state=42).copy()\n",
    "print(f\"âœ… Test set: {len(test_df):,} rows\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de10dd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Encoding categorical features...\n",
      "Found 45 categorical columns: ['customer_id', 'gender', 'language_x', 'created_at_x', 'updated_at_x', 'vendor_category_en', 'OpeningTime', 'OpeningTime2', 'is_haked_delivering', 'language_y']...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Categorical features encoded successfully!\n",
      "Dataset shape: (151400, 92)\n",
      "Test set shape: (15000, 92)\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”„ Encoding categorical features...\")\n",
    "\n",
    "# Get categorical columns\n",
    "categorical_cols = [col for col in train_full.columns if train_full[col].dtype == 'object']\n",
    "print(f\"Found {len(categorical_cols)} categorical columns: {categorical_cols[:10]}...\")\n",
    "\n",
    "# Encode categorical features\n",
    "for col in categorical_cols:\n",
    "    if col in test_df.columns:\n",
    "        le = LabelEncoder()\n",
    "        # Fit on combined data for consistency\n",
    "        combined_data = pd.concat([\n",
    "            train_full[col].astype(str).fillna('missing'),\n",
    "            test_df[col].astype(str).fillna('missing')\n",
    "        ])\n",
    "        le.fit(combined_data)\n",
    "        \n",
    "        # Transform both datasets\n",
    "        train_full[col] = le.transform(train_full[col].astype(str).fillna('missing'))\n",
    "        test_df[col] = le.transform(test_df[col].astype(str).fillna('missing'))\n",
    "\n",
    "print(\"âœ… Categorical features encoded successfully!\")\n",
    "print(f\"Dataset shape: {train_full.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e7b0d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸš€ ENHANCED MODEL TRAINING WITH ADVANCED TECHNIQUES\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ¯ STEP 1: Feature Selection\n",
      "Total available features: 83\n",
      "Sample features: ['gender', 'status', 'verified_x', 'language_x', 'authentication_id', 'vendor_lat', 'vendor_lon', 'vendor_category_en', 'vendor_category_id', 'delivery_charge']...\n",
      "Training set: (151400, 83)\n",
      "Test set: (15000, 83)\n",
      "Positive ratio: 0.0296\n",
      "\n",
      "ðŸŽ¯ STEP 2: Baseline Model with Cross-Validation\n",
      "ðŸ”„ Performing 5-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/5...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/5...\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/5...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/5...\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/5...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 4/5...\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 4/5...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 1\n",
      "    âœ… Fold 4 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 5/5...\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 1\n",
      "    âœ… Fold 4 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 5/5...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-29 09:29:58,368] A new study created in memory with name: no-name-dcbb8159-8131-4c34-bff0-161225177586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 1\n",
      "    âœ… Fold 5 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000', '1.0000', '1.0000']\n",
      "\n",
      "ðŸŽ¯ STEP 3: Hyperparameter Optimization\n",
      "Optimizing hyperparameters (this may take a few minutes)...\n",
      "ðŸ” Optimizing hyperparameters with 30 trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:   3%|â–Ž         | 1/30 [00:02<01:21,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:01,164] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 189, 'learning_rate': 0.05884162546465663, 'num_leaves': 39, 'feature_fraction': 0.5997284794492113, 'bagging_fraction': 0.8539030605765322, 'bagging_freq': 6, 'min_child_samples': 57, 'reg_alpha': 1.815104340467916, 'reg_lambda': 0.8725156333114288, 'min_split_gain': 0.7349099499624805}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:   7%|â–‹         | 2/30 [00:05<01:15,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:03,771] Trial 1 finished with value: 1.0 and parameters: {'n_estimators': 333, 'learning_rate': 0.09297053148004847, 'num_leaves': 19, 'feature_fraction': 0.6140884064151555, 'bagging_fraction': 0.5469510288632079, 'bagging_freq': 2, 'min_child_samples': 63, 'reg_alpha': 1.2462111523606836, 'reg_lambda': 0.11773167656976025, 'min_split_gain': 0.7347332448946956}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  10%|â–ˆ         | 3/30 [00:07<01:06,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:06,005] Trial 2 finished with value: 1.0 and parameters: {'n_estimators': 656, 'learning_rate': 0.04532627841301704, 'num_leaves': 18, 'feature_fraction': 0.6519150313076385, 'bagging_fraction': 0.5465426854680113, 'bagging_freq': 7, 'min_child_samples': 22, 'reg_alpha': 0.7824939633695851, 'reg_lambda': 0.47516772383153794, 'min_split_gain': 0.4819871374828417}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  13%|â–ˆâ–Ž        | 4/30 [00:10<01:07,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:08,822] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 630, 'learning_rate': 0.07493320434730799, 'num_leaves': 41, 'feature_fraction': 0.623370734918065, 'bagging_fraction': 0.6633615096904317, 'bagging_freq': 2, 'min_child_samples': 62, 'reg_alpha': 0.04402320641093893, 'reg_lambda': 0.7034815408856825, 'min_split_gain': 0.04170579326241941}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  17%|â–ˆâ–‹        | 5/30 [00:13<01:06,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:11,540] Trial 4 finished with value: 1.0 and parameters: {'n_estimators': 182, 'learning_rate': 0.027487671717249147, 'num_leaves': 50, 'feature_fraction': 0.6096711245914977, 'bagging_fraction': 0.7164782442258377, 'bagging_freq': 4, 'min_child_samples': 91, 'reg_alpha': 0.7980579230787452, 'reg_lambda': 1.7797806390531004, 'min_split_gain': 0.7906704627191311}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  20%|â–ˆâ–ˆ        | 6/30 [00:16<01:05,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:14,377] Trial 5 finished with value: 1.0 and parameters: {'n_estimators': 525, 'learning_rate': 0.06798786851046591, 'num_leaves': 10, 'feature_fraction': 0.6204794009285681, 'bagging_fraction': 0.865194740063677, 'bagging_freq': 5, 'min_child_samples': 48, 'reg_alpha': 1.5655483090501456, 'reg_lambda': 1.932371407638921, 'min_split_gain': 0.35484444379239444}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:18<00:59,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:16,677] Trial 6 finished with value: 1.0 and parameters: {'n_estimators': 460, 'learning_rate': 0.0815904913118423, 'num_leaves': 24, 'feature_fraction': 0.6778812764621951, 'bagging_fraction': 0.5652221119071017, 'bagging_freq': 1, 'min_child_samples': 176, 'reg_alpha': 1.7803397466051127, 'reg_lambda': 1.0332466128201168, 'min_split_gain': 0.17933024732089853}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:20<00:55,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:19,076] Trial 7 finished with value: 1.0 and parameters: {'n_estimators': 255, 'learning_rate': 0.023380779527354505, 'num_leaves': 49, 'feature_fraction': 0.8108204773296588, 'bagging_fraction': 0.8412058889643782, 'bagging_freq': 6, 'min_child_samples': 139, 'reg_alpha': 1.3947346104681297, 'reg_lambda': 1.9026645182265405, 'min_split_gain': 0.41344929519495077}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:22<00:50,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:21,260] Trial 8 finished with value: 1.0 and parameters: {'n_estimators': 119, 'learning_rate': 0.09662194628810532, 'num_leaves': 43, 'feature_fraction': 0.8746269177179736, 'bagging_fraction': 0.5610097962735794, 'bagging_freq': 3, 'min_child_samples': 143, 'reg_alpha': 1.9999896884314943, 'reg_lambda': 1.6613253947590247, 'min_split_gain': 0.6065190324797622}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:25<00:48,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:23,709] Trial 9 finished with value: 1.0 and parameters: {'n_estimators': 420, 'learning_rate': 0.0388617399346047, 'num_leaves': 33, 'feature_fraction': 0.6447221645210653, 'bagging_fraction': 0.6019427878115382, 'bagging_freq': 5, 'min_child_samples': 148, 'reg_alpha': 0.3798565676417034, 'reg_lambda': 1.7396256625225386, 'min_split_gain': 0.5830251482422739}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:28<00:50,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:26,856] Trial 10 finished with value: 1.0 and parameters: {'n_estimators': 790, 'learning_rate': 0.01116672020499919, 'num_leaves': 33, 'feature_fraction': 0.5279634588730531, 'bagging_fraction': 0.7808579008076486, 'bagging_freq': 7, 'min_child_samples': 101, 'reg_alpha': 1.1499009219473388, 'reg_lambda': 1.2136979357940427, 'min_split_gain': 0.9649899996650906}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:31<00:49,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:29,774] Trial 11 finished with value: 1.0 and parameters: {'n_estimators': 310, 'learning_rate': 0.09932161198546365, 'num_leaves': 23, 'feature_fraction': 0.5214204693216375, 'bagging_fraction': 0.5036011719685821, 'bagging_freq': 1, 'min_child_samples': 58, 'reg_alpha': 1.2147130664216792, 'reg_lambda': 0.03665896518917679, 'min_split_gain': 0.7927901131214845}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:33<00:44,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:32,210] Trial 12 finished with value: 1.0 and parameters: {'n_estimators': 317, 'learning_rate': 0.06149601675709099, 'num_leaves': 11, 'feature_fraction': 0.7239253987094261, 'bagging_fraction': 0.7493521662306132, 'bagging_freq': 3, 'min_child_samples': 78, 'reg_alpha': 1.6438696801215842, 'reg_lambda': 0.0042786334266240456, 'min_split_gain': 0.7818018940535856}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:36<00:44,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:35,355] Trial 13 finished with value: 1.0 and parameters: {'n_estimators': 233, 'learning_rate': 0.05172929825819493, 'num_leaves': 39, 'feature_fraction': 0.5669522353764447, 'bagging_fraction': 0.6493962895277594, 'bagging_freq': 5, 'min_child_samples': 25, 'reg_alpha': 1.995006558786429, 'reg_lambda': 0.430856542621392, 'min_split_gain': 0.9744126670653397}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:39<00:41,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:37,954] Trial 14 finished with value: 1.0 and parameters: {'n_estimators': 101, 'learning_rate': 0.08503667737451663, 'num_leaves': 27, 'feature_fraction': 0.7311855616249786, 'bagging_fraction': 0.8987375849295879, 'bagging_freq': 3, 'min_child_samples': 109, 'reg_alpha': 0.8480369764420158, 'reg_lambda': 1.3602253318238278, 'min_split_gain': 0.6777754873211554}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:42<00:40,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:41,108] Trial 15 finished with value: 1.0 and parameters: {'n_estimators': 368, 'learning_rate': 0.08767685658168242, 'num_leaves': 19, 'feature_fraction': 0.5667380534906795, 'bagging_fraction': 0.7988167978297032, 'bagging_freq': 2, 'min_child_samples': 43, 'reg_alpha': 1.3851388560658604, 'reg_lambda': 0.7376194612877542, 'min_split_gain': 0.7128164387581672}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:45<00:36,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:43,798] Trial 16 finished with value: 1.0 and parameters: {'n_estimators': 196, 'learning_rate': 0.06420059562909333, 'num_leaves': 35, 'feature_fraction': 0.7641908563768869, 'bagging_fraction': 0.6406525369289499, 'bagging_freq': 6, 'min_child_samples': 76, 'reg_alpha': 0.44632062534813555, 'reg_lambda': 0.2829857887644751, 'min_split_gain': 0.8604928404361614}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:48<00:34,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:46,923] Trial 17 finished with value: 1.0 and parameters: {'n_estimators': 506, 'learning_rate': 0.05439908212420012, 'num_leaves': 17, 'feature_fraction': 0.5647860603441592, 'bagging_fraction': 0.7057471124918768, 'bagging_freq': 4, 'min_child_samples': 127, 'reg_alpha': 1.7454833077567071, 'reg_lambda': 0.7962362221365167, 'min_split_gain': 0.5560708381570731}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:51<00:31,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:49,615] Trial 18 finished with value: 1.0 and parameters: {'n_estimators': 315, 'learning_rate': 0.07533777302107846, 'num_leaves': 29, 'feature_fraction': 0.6895749584350656, 'bagging_fraction': 0.8117598314160637, 'bagging_freq': 2, 'min_child_samples': 85, 'reg_alpha': 1.0528626334898505, 'reg_lambda': 1.467221191813814, 'min_split_gain': 0.34115152483252076}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:54<00:29,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:52,746] Trial 19 finished with value: 1.0 and parameters: {'n_estimators': 397, 'learning_rate': 0.036404364994329946, 'num_leaves': 37, 'feature_fraction': 0.5013363661316367, 'bagging_fraction': 0.7444311384697402, 'bagging_freq': 6, 'min_child_samples': 198, 'reg_alpha': 1.3296134642037996, 'reg_lambda': 1.0127187967887712, 'min_split_gain': 0.6774734402295232}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:56<00:25,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:55,360] Trial 20 finished with value: 1.0 and parameters: {'n_estimators': 165, 'learning_rate': 0.08963015897952166, 'num_leaves': 43, 'feature_fraction': 0.5901501794566016, 'bagging_fraction': 0.501696976284047, 'bagging_freq': 4, 'min_child_samples': 43, 'reg_alpha': 1.5669217929584867, 'reg_lambda': 0.245800777586333, 'min_split_gain': 0.8839592554752236}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:59<00:21,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:30:57,709] Trial 21 finished with value: 1.0 and parameters: {'n_estimators': 664, 'learning_rate': 0.04407350193054284, 'num_leaves': 16, 'feature_fraction': 0.6656412327630278, 'bagging_fraction': 0.545274080132154, 'bagging_freq': 7, 'min_child_samples': 20, 'reg_alpha': 0.6404462575637646, 'reg_lambda': 0.5338501852416256, 'min_split_gain': 0.470839238147025}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [01:01<00:18,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:31:00,033] Trial 22 finished with value: 1.0 and parameters: {'n_estimators': 621, 'learning_rate': 0.04314238424600754, 'num_leaves': 22, 'feature_fraction': 0.6432219303844277, 'bagging_fraction': 0.6058855963637315, 'bagging_freq': 7, 'min_child_samples': 36, 'reg_alpha': 0.9627589207173168, 'reg_lambda': 0.5259032449092198, 'min_split_gain': 0.2574935870398362}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [01:04<00:15,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:31:02,725] Trial 23 finished with value: 1.0 and parameters: {'n_estimators': 783, 'learning_rate': 0.05033407099503048, 'num_leaves': 13, 'feature_fraction': 0.5875598073225028, 'bagging_fraction': 0.6061665404688001, 'bagging_freq': 6, 'min_child_samples': 67, 'reg_alpha': 0.6107741667181437, 'reg_lambda': 0.22382203245110932, 'min_split_gain': 0.5685770901629141}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [01:06<00:13,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:31:05,353] Trial 24 finished with value: 1.0 and parameters: {'n_estimators': 725, 'learning_rate': 0.02474069229711516, 'num_leaves': 20, 'feature_fraction': 0.727048210188485, 'bagging_fraction': 0.5370454605815718, 'bagging_freq': 7, 'min_child_samples': 32, 'reg_alpha': 0.27119218189748184, 'reg_lambda': 0.8578354455571287, 'min_split_gain': 0.48190158034599795}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [01:09<00:10,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:31:07,638] Trial 25 finished with value: 1.0 and parameters: {'n_estimators': 260, 'learning_rate': 0.07125969713572618, 'num_leaves': 26, 'feature_fraction': 0.6509615153733418, 'bagging_fraction': 0.5859750625243519, 'bagging_freq': 6, 'min_child_samples': 53, 'reg_alpha': 0.7159872472544411, 'reg_lambda': 0.41937100918072556, 'min_split_gain': 0.655584491268842}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [01:11<00:07,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:31:10,171] Trial 26 finished with value: 1.0 and parameters: {'n_estimators': 565, 'learning_rate': 0.058952623984265456, 'num_leaves': 15, 'feature_fraction': 0.7667681337102632, 'bagging_fraction': 0.6680774177008962, 'bagging_freq': 5, 'min_child_samples': 69, 'reg_alpha': 0.965853512549761, 'reg_lambda': 0.6161308090178187, 'min_split_gain': 0.7594364804956032}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [01:14<00:04,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:31:12,554] Trial 27 finished with value: 1.0 and parameters: {'n_estimators': 360, 'learning_rate': 0.0309545341503454, 'num_leaves': 46, 'feature_fraction': 0.6971054871189013, 'bagging_fraction': 0.5257351272998524, 'bagging_freq': 7, 'min_child_samples': 30, 'reg_alpha': 1.8157457261432486, 'reg_lambda': 0.12268744206742298, 'min_split_gain': 0.8513478387396535}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [01:17<00:02,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:31:15,729] Trial 28 finished with value: 1.0 and parameters: {'n_estimators': 464, 'learning_rate': 0.01578966561480665, 'num_leaves': 20, 'feature_fraction': 0.5547607897076672, 'bagging_fraction': 0.6297237914122806, 'bagging_freq': 4, 'min_child_samples': 101, 'reg_alpha': 1.2290282997703799, 'reg_lambda': 0.37608306523090773, 'min_split_gain': 0.4241733951865205}. Best is trial 0 with value: 1.0.\n",
      "ðŸ”„ Performing 3-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/3...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [01:20<00:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000']\n",
      "[I 2025-07-29 09:31:18,616] Trial 29 finished with value: 1.0 and parameters: {'n_estimators': 608, 'learning_rate': 0.04629826496900096, 'num_leaves': 30, 'feature_fraction': 0.6025283105123058, 'bagging_fraction': 0.6706788705324463, 'bagging_freq': 2, 'min_child_samples': 58, 'reg_alpha': 0.035047683222585, 'reg_lambda': 1.1756118109482956, 'min_split_gain': 0.2866130416835142}. Best is trial 0 with value: 1.0.\n",
      "ðŸ† Best hyperparameters found:\n",
      "  â€¢ n_estimators: 189\n",
      "  â€¢ learning_rate: 0.05884162546465663\n",
      "  â€¢ num_leaves: 39\n",
      "  â€¢ feature_fraction: 0.5997284794492113\n",
      "  â€¢ bagging_fraction: 0.8539030605765322\n",
      "  â€¢ bagging_freq: 6\n",
      "  â€¢ min_child_samples: 57\n",
      "  â€¢ reg_alpha: 1.815104340467916\n",
      "  â€¢ reg_lambda: 0.8725156333114288\n",
      "  â€¢ min_split_gain: 0.7349099499624805\n",
      "ðŸŽ¯ Best CV AUC: 1.0000\n",
      "\n",
      "ðŸ“‹ Final model parameters:\n",
      "  â€¢ objective: binary\n",
      "  â€¢ metric: auc\n",
      "  â€¢ boosting_type: gbdt\n",
      "  â€¢ n_estimators: 189\n",
      "  â€¢ learning_rate: 0.05884162546465663\n",
      "  â€¢ num_leaves: 39\n",
      "  â€¢ feature_fraction: 0.5997284794492113\n",
      "  â€¢ bagging_fraction: 0.8539030605765322\n",
      "  â€¢ bagging_freq: 6\n",
      "  â€¢ verbose: -1\n",
      "  â€¢ random_state: 42\n",
      "  â€¢ n_jobs: -1\n",
      "  â€¢ min_child_samples: 57\n",
      "  â€¢ reg_alpha: 1.815104340467916\n",
      "  â€¢ reg_lambda: 0.8725156333114288\n",
      "  â€¢ min_split_gain: 0.7349099499624805\n",
      "\n",
      "ðŸŽ¯ STEP 4: Training Final Ensemble Model\n",
      "ðŸ”„ Performing 5-fold cross-validation...\n",
      "  ðŸ“Š Training fold 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/5...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 1 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 2/5...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/5...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 2 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 3/5...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 4/5...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 3 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 4/5...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 4 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 5/5...\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 4 AUC: 1.0000\n",
      "  ðŸ“Š Training fold 5/5...\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 5 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000', '1.0000', '1.0000']\n",
      "\n",
      "ðŸ“Š PERFORMANCE COMPARISON:\n",
      "â€¢ Baseline CV AUC:  1.0000\n",
      "â€¢ Optimized CV AUC: 1.0000\n",
      "â€¢ Improvement:      0.0000\n",
      "\n",
      "ðŸŽ¯ STEP 5: Feature Importance Analysis\n",
      "ðŸ” Top 20 Most Important Features:\n",
      "   1. customer_vendor_orders              1.0000\n",
      "   2. status                              0.0000\n",
      "   3. gender                              0.0000\n",
      "   4. language_x                          0.0000\n",
      "   5. authentication_id                   0.0000\n",
      "   6. vendor_lat                          0.0000\n",
      "   7. vendor_lon                          0.0000\n",
      "   8. vendor_category_en                  0.0000\n",
      "   9. vendor_category_id                  0.0000\n",
      "  10. delivery_charge                     0.0000\n",
      "  11. serving_distance                    0.0000\n",
      "  12. is_open                             0.0000\n",
      "  13. OpeningTime                         0.0000\n",
      "  14. OpeningTime2                        0.0000\n",
      "  15. prepration_time                     0.0000\n",
      "  16. commission                          0.0000\n",
      "  17. is_haked_delivering                 0.0000\n",
      "  18. discount_percentage                 0.0000\n",
      "  19. verified_x                          0.0000\n",
      "  20. vendor_status                       0.0000\n",
      "\n",
      "âœ… ENHANCED MODEL TRAINING COMPLETE!\n",
      "ðŸ“ˆ Final CV AUC Score: 1.0000\n",
      "ðŸŽ¯ Ready for enhanced predictions!\n",
      "================================================================================\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\n",
      "    âœ… Fold 5 AUC: 1.0000\n",
      "ðŸŽ¯ Cross-validation results:\n",
      "  â€¢ Mean AUC: 1.0000 (+/- 0.0000)\n",
      "  â€¢ Individual folds: ['1.0000', '1.0000', '1.0000', '1.0000', '1.0000']\n",
      "\n",
      "ðŸ“Š PERFORMANCE COMPARISON:\n",
      "â€¢ Baseline CV AUC:  1.0000\n",
      "â€¢ Optimized CV AUC: 1.0000\n",
      "â€¢ Improvement:      0.0000\n",
      "\n",
      "ðŸŽ¯ STEP 5: Feature Importance Analysis\n",
      "ðŸ” Top 20 Most Important Features:\n",
      "   1. customer_vendor_orders              1.0000\n",
      "   2. status                              0.0000\n",
      "   3. gender                              0.0000\n",
      "   4. language_x                          0.0000\n",
      "   5. authentication_id                   0.0000\n",
      "   6. vendor_lat                          0.0000\n",
      "   7. vendor_lon                          0.0000\n",
      "   8. vendor_category_en                  0.0000\n",
      "   9. vendor_category_id                  0.0000\n",
      "  10. delivery_charge                     0.0000\n",
      "  11. serving_distance                    0.0000\n",
      "  12. is_open                             0.0000\n",
      "  13. OpeningTime                         0.0000\n",
      "  14. OpeningTime2                        0.0000\n",
      "  15. prepration_time                     0.0000\n",
      "  16. commission                          0.0000\n",
      "  17. is_haked_delivering                 0.0000\n",
      "  18. discount_percentage                 0.0000\n",
      "  19. verified_x                          0.0000\n",
      "  20. vendor_status                       0.0000\n",
      "\n",
      "âœ… ENHANCED MODEL TRAINING COMPLETE!\n",
      "ðŸ“ˆ Final CV AUC Score: 1.0000\n",
      "ðŸŽ¯ Ready for enhanced predictions!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ðŸš€ ENHANCED MODEL TRAINING WITH ADVANCED TECHNIQUES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Step 1: Prepare features and target\n",
    "print(\"\\nðŸŽ¯ STEP 1: Feature Selection\")\n",
    "\n",
    "# Define features to exclude\n",
    "exclude_features = [\n",
    "    'target', 'customer_id', 'vendor_id', 'id', 'dob', \n",
    "    'created_at_x', 'updated_at_x', 'created_at_y', 'updated_at_y',\n",
    "    'customer_first_order', 'customer_last_order', 'customer_vendor_last_order'\n",
    "]\n",
    "\n",
    "# Select features that exist in both datasets\n",
    "available_features = [col for col in train_full.columns \n",
    "                     if col not in exclude_features and col in test_df.columns]\n",
    "\n",
    "print(f\"Total available features: {len(available_features)}\")\n",
    "print(f\"Sample features: {available_features[:10]}...\")\n",
    "\n",
    "X = train_full[available_features]\n",
    "y = train_full['target']\n",
    "X_test = test_df[available_features]\n",
    "\n",
    "print(f\"Training set: {X.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Positive ratio: {y.mean():.4f}\")\n",
    "\n",
    "# Step 2: Baseline model with cross-validation\n",
    "print(\"\\nðŸŽ¯ STEP 2: Baseline Model with Cross-Validation\")\n",
    "\n",
    "# Baseline parameters\n",
    "baseline_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Cross-validation\n",
    "baseline_cv_score, baseline_models = cross_validate_model(X, y, baseline_params, n_folds=5)\n",
    "\n",
    "# Step 3: Hyperparameter optimization\n",
    "print(\"\\nðŸŽ¯ STEP 3: Hyperparameter Optimization\")\n",
    "print(\"Optimizing hyperparameters (this may take a few minutes)...\")\n",
    "\n",
    "best_params = optimize_hyperparameters(X, y, n_trials=30, random_state=42)\n",
    "\n",
    "# Update baseline params with optimized values\n",
    "final_params = baseline_params.copy()\n",
    "final_params.update(best_params)\n",
    "\n",
    "print(f\"\\nðŸ“‹ Final model parameters:\")\n",
    "for key, value in final_params.items():\n",
    "    print(f\"  â€¢ {key}: {value}\")\n",
    "\n",
    "# Step 4: Train ensemble model with optimized parameters\n",
    "print(\"\\nðŸŽ¯ STEP 4: Training Final Ensemble Model\")\n",
    "\n",
    "final_cv_score, ensemble_models = cross_validate_model(X, y, final_params, n_folds=5)\n",
    "\n",
    "# Compare performance\n",
    "print(f\"\\nðŸ“Š PERFORMANCE COMPARISON:\")\n",
    "print(f\"â€¢ Baseline CV AUC:  {baseline_cv_score:.4f}\")\n",
    "print(f\"â€¢ Optimized CV AUC: {final_cv_score:.4f}\")\n",
    "print(f\"â€¢ Improvement:      {final_cv_score - baseline_cv_score:.4f}\")\n",
    "\n",
    "# Step 5: Feature importance analysis\n",
    "print(\"\\nðŸŽ¯ STEP 5: Feature Importance Analysis\")\n",
    "\n",
    "# Calculate feature importance from the ensemble\n",
    "feature_importance = np.zeros(len(available_features))\n",
    "for model in ensemble_models:\n",
    "    feature_importance += model.feature_importances_\n",
    "\n",
    "feature_importance /= len(ensemble_models)\n",
    "\n",
    "# Create feature importance dataframe\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': available_features,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"ðŸ” Top 20 Most Important Features:\")\n",
    "for i, (_, row) in enumerate(importance_df.head(20).iterrows()):\n",
    "    print(f\"  {i+1:2d}. {row['feature']:<35} {row['importance']:.4f}\")\n",
    "\n",
    "# Store final model and results\n",
    "model = ensemble_models[0]  # Use first model for predictions (they're all similar)\n",
    "features = available_features\n",
    "\n",
    "print(f\"\\nâœ… ENHANCED MODEL TRAINING COMPLETE!\")\n",
    "print(f\"ðŸ“ˆ Final CV AUC Score: {final_cv_score:.4f}\")\n",
    "print(f\"ðŸŽ¯ Ready for enhanced predictions!\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89b61070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸš€ FAST SUBMISSION GENERATION WITH ENSEMBLE PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ¯ STEP 1: Creating Fast Test Data\n",
      "Optimized test data generation...\n",
      "Created 127 test combinations to predict\n",
      "\n",
      "ðŸŽ¯ STEP 2: Fast Feature Preparation\n",
      "Test data prepared: (268, 92)\n",
      "\n",
      "ðŸŽ¯ STEP 3: Fast Encoding\n",
      "\n",
      "ðŸŽ¯ STEP 4: Fast Predictions\n",
      "Using 83 features for prediction\n",
      "\n",
      "ðŸŽ¯ STEP 5: Creating Submission File\n",
      "âœ… Train submission created with 268 predictions!\n",
      "âœ… Saved to: Train/train_submission.csv\n",
      "\n",
      "ðŸŽ¯ STEP 6: Quick Analysis\n",
      "\n",
      "ðŸ“Š PREDICTION STATISTICS:\n",
      "â€¢ Mean prediction: 0.038047\n",
      "â€¢ Min prediction:  0.027887\n",
      "â€¢ Max prediction:  0.179160\n",
      "â€¢ Total predictions: 268\n",
      "\n",
      "ðŸ” TOP 10 RECOMMENDATIONS:\n",
      "   CID X LOC_NUM X VENDOR   target\n",
      "53       URLP7T1 X 3 X 86  0.17916\n",
      "51       URLP7T1 X 3 X 86  0.17916\n",
      "50       URLP7T1 X 3 X 86  0.17916\n",
      "45      URLP7T1 X 1 X 271  0.17916\n",
      "44      URLP7T1 X 1 X 271  0.17916\n",
      "43      URLP7T1 X 1 X 271  0.17916\n",
      "42      URLP7T1 X 1 X 271  0.17916\n",
      "52       URLP7T1 X 3 X 86  0.17916\n",
      "84       HEHQN0I X 3 X 13  0.17916\n",
      "83       HEHQN0I X 3 X 13  0.17916\n",
      "\n",
      "ðŸ“ˆ SUMMARY:\n",
      "â€¢ Enhanced model with 83 features\n",
      "â€¢ Ensemble of 5 optimized models\n",
      "â€¢ File saved: Train/train_submission.csv\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ðŸš€ FAST SUBMISSION GENERATION WITH ENSEMBLE PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Step 1: Create optimized test combinations (quick generation)\n",
    "print(\"\\nðŸŽ¯ STEP 1: Creating Fast Test Data\")\n",
    "print(\"Optimized test data generation...\")\n",
    "\n",
    "# Reduce sample size for speed - smaller but representative sample\n",
    "test_customers = np.random.choice(all_customers, size=min(50, len(all_customers)), replace=False)\n",
    "test_combinations = []\n",
    "\n",
    "for customer in test_customers:\n",
    "    # Reduce combinations per customer for speed\n",
    "    num_combinations = np.random.randint(2, 4)  # 2-3 combinations per customer\n",
    "    customer_vendors = np.random.choice(all_vendors, size=num_combinations, replace=False)\n",
    "    \n",
    "    for i, vendor in enumerate(customer_vendors):\n",
    "        test_combinations.append({\n",
    "            'customer_id': customer,\n",
    "            'LOCATION_NUMBER': i + 1,\n",
    "            'vendor_id': vendor\n",
    "        })\n",
    "\n",
    "test_input_df = pd.DataFrame(test_combinations)\n",
    "print(f\"Created {len(test_input_df):,} test combinations to predict\")\n",
    "\n",
    "# Step 2: Fast feature preparation\n",
    "print(\"\\nðŸŽ¯ STEP 2: Fast Feature Preparation\")\n",
    "\n",
    "# Merge with basic data (optimized)\n",
    "test_prepared = test_input_df.merge(train_customers, on='customer_id', how='left')\n",
    "test_prepared = test_prepared.merge(vendors_renamed, left_on='vendor_id', right_on='id', how='left')\n",
    "test_prepared = test_prepared.merge(train_locations, on='customer_id', how='left')\n",
    "\n",
    "# Apply basic feature engineering\n",
    "test_prepared = feature_engineer(test_prepared)\n",
    "\n",
    "# Merge advanced features (same as training)\n",
    "test_prepared = test_prepared.merge(customer_features, on='customer_id', how='left')\n",
    "test_prepared = test_prepared.merge(vendor_features, on='vendor_id', how='left')\n",
    "test_prepared = test_prepared.merge(interaction_features, on=['customer_id', 'vendor_id'], how='left')\n",
    "\n",
    "# Fast missing value handling\n",
    "numeric_cols = test_prepared.select_dtypes(include=[np.number]).columns\n",
    "test_prepared[numeric_cols] = test_prepared[numeric_cols].fillna(0)\n",
    "\n",
    "categorical_cols = test_prepared.select_dtypes(include=['object']).columns\n",
    "test_prepared[categorical_cols] = test_prepared[categorical_cols].fillna('unknown')\n",
    "\n",
    "print(f\"Test data prepared: {test_prepared.shape}\")\n",
    "\n",
    "# Step 3: Fast categorical encoding\n",
    "print(\"\\nðŸŽ¯ STEP 3: Fast Encoding\")\n",
    "categorical_cols = [col for col in test_prepared.columns if test_prepared[col].dtype == 'object']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in features:  # Only encode features used in training\n",
    "        le = LabelEncoder()\n",
    "        test_prepared[col] = le.fit_transform(test_prepared[col].astype(str).fillna('missing'))\n",
    "\n",
    "# Step 4: Fast ensemble predictions\n",
    "print(\"\\nðŸŽ¯ STEP 4: Fast Predictions\")\n",
    "test_features = test_prepared[features]\n",
    "print(f\"Using {len(features)} features for prediction\")\n",
    "\n",
    "# Use ensemble prediction (averaging across all trained models)\n",
    "ensemble_predictions = predict_with_ensemble(ensemble_models, test_features)\n",
    "\n",
    "# Step 5: Create submission file\n",
    "print(\"\\nðŸŽ¯ STEP 5: Creating Submission File\")\n",
    "\n",
    "# Create submission format\n",
    "test_prepared['CID X LOC_NUM X VENDOR'] = (\n",
    "    test_prepared['customer_id'].astype(str) + ' X ' + \n",
    "    test_prepared['LOCATION_NUMBER'].astype(str) + ' X ' + \n",
    "    test_prepared['vendor_id'].astype(str)\n",
    ")\n",
    "\n",
    "test_prepared['target'] = ensemble_predictions\n",
    "\n",
    "# Create final submission\n",
    "submission_file = test_prepared[['CID X LOC_NUM X VENDOR', 'target']].copy()\n",
    "\n",
    "# Sort by prediction probability (highest first)\n",
    "submission_file = submission_file.sort_values('target', ascending=False)\n",
    "\n",
    "# Save to Train folder with new filename\n",
    "submission_file.to_csv('Train/train_submission.csv', index=False)\n",
    "\n",
    "print(f\"âœ… Train submission created with {len(submission_file):,} predictions!\")\n",
    "print(f\"âœ… Saved to: Train/train_submission.csv\")\n",
    "\n",
    "# Step 6: Quick analysis\n",
    "print(\"\\nðŸŽ¯ STEP 6: Quick Analysis\")\n",
    "\n",
    "print(f\"\\nðŸ“Š PREDICTION STATISTICS:\")\n",
    "print(f\"â€¢ Mean prediction: {ensemble_predictions.mean():.6f}\")\n",
    "print(f\"â€¢ Min prediction:  {ensemble_predictions.min():.6f}\")\n",
    "print(f\"â€¢ Max prediction:  {ensemble_predictions.max():.6f}\")\n",
    "print(f\"â€¢ Total predictions: {len(ensemble_predictions):,}\")\n",
    "\n",
    "print(f\"\\nðŸ” TOP 10 RECOMMENDATIONS:\")\n",
    "print(submission_file.head(10))\n",
    "\n",
    "print(f\"\\nðŸ“ˆ SUMMARY:\")\n",
    "print(f\"â€¢ Enhanced model with {len(features)} features\")\n",
    "print(f\"â€¢ Ensemble of {len(ensemble_models)} optimized models\")\n",
    "print(f\"â€¢ File saved: Train/train_submission.csv\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
